{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05def135-b0f6-457f-b6f2-fa040f830e34",
   "metadata": {},
   "source": [
    "# Entremamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea23425-59c3-4965-a5df-5ad5b951ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Añadir el directorio raíz al path para poder importar módulos personalizados\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils import config\n",
    "from utils import neural_network_functions as nnf\n",
    "from utils import preprocessing_functions as pf\n",
    "from utils import evaluation_functions as ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c3e1cf6-62f8-4820-9b1f-ea8d7a0306b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils.config' has no attribute 'RANDOM_STATE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Dividir en conjunto de entrenamiento y validación\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m pf\u001b[38;5;241m.\u001b[39mtrain_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train shape : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_valid shape : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_valid\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'utils.config' has no attribute 'RANDOM_STATE'"
     ]
    }
   ],
   "source": [
    "# 1. Cargar los datos de entrenamiento y validación\n",
    "# Cargar el dataset normalizado\n",
    "train_df = pd.read_csv(\"../data/processed/train_set_normalized.csv\")\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = train_df.drop('diagnosis', axis=1).values\n",
    "y = train_df['diagnosis'].values\n",
    "\n",
    "# Convertir etiquetas a formato adecuado\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y validación\n",
    "X_train, X_valid, y_train, y_valid = pf.train_test_split(X, y, test_size=0.2, random_state=config.RANDOM_STATE)\n",
    "\n",
    "print(f\"x_train shape : {X_train.shape}\")\n",
    "print(f\"x_valid shape : {X_valid.shape}\")\n",
    "\n",
    "# 2. Definir la arquitectura de la red neuronal\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = 1\n",
    "\n",
    "network = nnf.createNetwork([\n",
    "    nnf.denseLayer(input_shape, 25, activation=\"sigmoid\", weights_initializer=\"he_uniform\"),\n",
    "    nnf.denseLayer(25, 25, activation=\"sigmoid\", weights_initializer=\"he_uniform\"),\n",
    "    nnf.denseLayer(25, output_shape, activation=\"sigmoid\", weights_initializer=\"he_uniform\")\n",
    "])\n",
    "\n",
    "# 3. Definir hiperparámetros y parámetro de loss function\n",
    "learning_rate = config.LEARNING_RATE\n",
    "epochs = config.EPOCHS\n",
    "batch_size = config.BATCH_SIZE\n",
    "loss_function = \"binary_crossentropy\"\n",
    "\n",
    "# 4. Entrenar el modelo\n",
    "history = nnf.fit(network, X_train, y_train, X_valid, y_valid,\n",
    "                    loss=loss_function,\n",
    "                    learning_rate=learning_rate,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs)\n",
    "\n",
    "# 5. Guardar el modelo entrenado en formato JSON\n",
    "model_filepath = \"./output/models/saved_model.json\" # Cambiamos la extensión a .json\n",
    "nnf.guardar_modelo_json(network, model_filepath)\n",
    "print(f\"# saving model \\\"{model_filepath}\\\" to disk...\")\n",
    "\n",
    "# 6. Calcular Accuracy en el conjunto de validación\n",
    "predictions_valid = nnf.predict(network, X_valid) # Función predict que debes implementar\n",
    "accuracy_valid = ef.accuracy(y_valid, predictions_valid) # Usamos la función accuracy de evaluation_functions\n",
    "print(f\"Validation Accuracy: {accuracy_valid:.4f}\")\n",
    "\n",
    "\n",
    "# 7. Visualizar el entrenamiento (opcional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa6848-58bd-43e7-98a3-d424f5c170f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
