{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d880fbaf-4600-44a1-8958-11692e7072ae",
   "metadata": {},
   "source": [
    "# breast_cancer resuelto SIN la librería sklearn\n",
    "Normalizando los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513b6b9e-ecd2-46ef-88b6-02d66d8abc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb765c1-c49f-416f-a621-03ebb82cb696",
   "metadata": {},
   "source": [
    "## Funciones para la normalización, entrenamiento y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc6c3da-aadc-4c99-9b68-804b0f4d8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScalerManual:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Calcula la media y desviación estándar de X.\"\"\"\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.scale_ = np.std(X, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Normaliza X usando la media y desviación estándar.\"\"\"\n",
    "        return (X - self.mean_) / self.scale_\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Ajusta el scaler a X y devuelve X normalizado.\"\"\"\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "class PerceptronManual:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el perceptrón usando el conjunto de datos X e y.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Inicializar pesos y bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Entrenamiento\n",
    "        for _ in range(self.n_iterations):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                # Predicción\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = 1 if linear_output > 0 else 0\n",
    "                \n",
    "                # Actualización de pesos si hay error\n",
    "                if y_predicted != y[idx]:\n",
    "                    update = self.learning_rate * (y[idx] - y_predicted)\n",
    "                    self.weights += update * x_i\n",
    "                    self.bias += update\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Realiza predicciones para el conjunto X.\"\"\"\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output > 0, 1, 0)\n",
    "\n",
    "def train_test_split_manual(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"División manual de datos en conjuntos de entrenamiento y prueba.\"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_test = int(n_samples * test_size)\n",
    "    \n",
    "    # Crear índices aleatorios\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    \n",
    "    # Dividir los datos\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def accuracy_score_manual(y_true, y_pred):\n",
    "    \"\"\"Calcula la precisión del modelo.\"\"\"\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def classification_report_manual(y_true, y_pred):\n",
    "    \"\"\"Genera un reporte de clasificación manual.\"\"\"\n",
    "    # Calcular verdaderos positivos, falsos positivos, etc.\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Calcular métricas\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224d1fd-c903-4319-a79b-4e49042af60b",
   "metadata": {},
   "source": [
    "## Cargar, preparar y normalizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75435e2a-0804-4b38-afc7-549a6076a2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeros registros del dataset:\n",
      "\n",
      "====  ===========  ========  ========  ========  =========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  =========  ========  ========  ========  ========  ========  ========\n",
      "  ..    diagnosis    feat01    feat02    feat03     feat04    feat05    feat06    feat07    feat08    feat09    feat10    feat11    feat12    feat13    feat14    feat15    feat16    feat17    feat18    feat19    feat20    feat21    feat22    feat23     feat24    feat25    feat26    feat27    feat28    feat29    feat30\n",
      "====  ===========  ========  ========  ========  =========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  =========  ========  ========  ========  ========  ========  ========\n",
      "   0       0.0000   17.9900   10.3800  122.8000  1001.0000    0.1184    0.2776    0.3001    0.1471    0.2419    0.0787    1.0950    0.9053    8.5890  153.4000    0.0064    0.0490    0.0537    0.0159    0.0300    0.0062   25.3800   17.3300  184.6000  2019.0000    0.1622    0.6656    0.7119    0.2654    0.4601    0.1189\n",
      "   1       0.0000   20.5700   17.7700  132.9000  1326.0000    0.0847    0.0786    0.0869    0.0702    0.1812    0.0567    0.5435    0.7339    3.3980   74.0800    0.0052    0.0131    0.0186    0.0134    0.0139    0.0035   24.9900   23.4100  158.8000  1956.0000    0.1238    0.1866    0.2416    0.1860    0.2750    0.0890\n",
      "   2       0.0000   19.6900   21.2500  130.0000  1203.0000    0.1096    0.1599    0.1974    0.1279    0.2069    0.0600    0.7456    0.7869    4.5850   94.0300    0.0062    0.0401    0.0383    0.0206    0.0225    0.0046   23.5700   25.5300  152.5000  1709.0000    0.1444    0.4245    0.4504    0.2430    0.3613    0.0876\n",
      "   3       0.0000   11.4200   20.3800   77.5800   386.1000    0.1425    0.2839    0.2414    0.1052    0.2597    0.0974    0.4956    1.1560    3.4450   27.2300    0.0091    0.0746    0.0566    0.0187    0.0596    0.0092   14.9100   26.5000   98.8700   567.7000    0.2098    0.8663    0.6869    0.2575    0.6638    0.1730\n",
      "   4       0.0000   20.2900   14.3400  135.1000  1297.0000    0.1003    0.1328    0.1980    0.1043    0.1809    0.0588    0.7572    0.7813    5.4380   94.4400    0.0115    0.0246    0.0569    0.0188    0.0176    0.0051   22.5400   16.6700  152.2000  1575.0000    0.1374    0.2050    0.4000    0.1625    0.2364    0.0768\n",
      "   5       0.0000   12.4500   15.7000   82.5700   477.1000    0.1278    0.1700    0.1578    0.0809    0.2087    0.0761    0.3345    0.8902    2.2170   27.1900    0.0075    0.0335    0.0367    0.0114    0.0216    0.0051   15.4700   23.7500  103.4000   741.6000    0.1791    0.5249    0.5355    0.1741    0.3985    0.1244\n",
      "   6       0.0000   18.2500   19.9800  119.6000  1040.0000    0.0946    0.1090    0.1127    0.0740    0.1794    0.0574    0.4467    0.7732    3.1800   53.9100    0.0043    0.0138    0.0225    0.0104    0.0137    0.0022   22.8800   27.6600  153.2000  1606.0000    0.1442    0.2576    0.3784    0.1932    0.3063    0.0837\n",
      "   7       0.0000   13.7100   20.8300   90.2000   577.9000    0.1189    0.1645    0.0937    0.0599    0.2196    0.0745    0.5835    1.3770    3.8560   50.9600    0.0088    0.0303    0.0249    0.0145    0.0149    0.0054   17.0600   28.1400  110.6000   897.0000    0.1654    0.3682    0.2678    0.1556    0.3196    0.1151\n",
      "   8       0.0000   13.0000   21.8200   87.5000   519.8000    0.1273    0.1932    0.1859    0.0935    0.2350    0.0739    0.3063    1.0020    2.4060   24.3200    0.0057    0.0350    0.0355    0.0123    0.0214    0.0037   15.4900   30.7300  106.2000   739.3000    0.1703    0.5401    0.5390    0.2060    0.4378    0.1072\n",
      "   9       0.0000   12.4600   24.0400   83.9700   475.9000    0.1186    0.2396    0.2273    0.0854    0.2030    0.0824    0.2976    1.5990    2.0390   23.9400    0.0071    0.0722    0.0774    0.0143    0.0179    0.0101   15.0900   40.6800   97.6500   711.4000    0.1853    1.0580    1.1050    0.2210    0.4366    0.2075\n",
      "  10       0.0000   16.0200   23.2400  102.7000   797.8000    0.0821    0.0667    0.0330    0.0332    0.1528    0.0570    0.3795    1.1870    2.4660   40.5100    0.0040    0.0093    0.0110    0.0076    0.0146    0.0030   19.1900   33.8800  123.8000  1150.0000    0.1181    0.1551    0.1459    0.0998    0.2948    0.0845\n",
      "  11       0.0000   15.7800   17.8900  103.6000   781.0000    0.0971    0.1292    0.0995    0.0661    0.1842    0.0608    0.5058    0.9849    3.5640   54.1600    0.0058    0.0406    0.0279    0.0128    0.0201    0.0041   20.4200   27.2800  136.5000  1299.0000    0.1396    0.5609    0.3965    0.1810    0.3792    0.1048\n",
      "  12       0.0000   19.1700   24.8000  132.4000  1123.0000    0.0974    0.2458    0.2065    0.1118    0.2397    0.0780    0.9555    3.5680   11.0700  116.2000    0.0031    0.0830    0.0889    0.0409    0.0448    0.0128   20.9600   29.9400  151.7000  1332.0000    0.1037    0.3903    0.3639    0.1767    0.3176    0.1023\n",
      "  13       0.0000   15.8500   23.9500  103.7000   782.7000    0.0840    0.1002    0.0994    0.0536    0.1847    0.0534    0.4033    1.0780    2.9030   36.5800    0.0098    0.0313    0.0505    0.0199    0.0298    0.0030   16.8400   27.6600  112.0000   876.5000    0.1131    0.1924    0.2322    0.1119    0.2809    0.0629\n",
      "  14       0.0000   13.7300   22.6100   93.6000   578.3000    0.1131    0.2293    0.2128    0.0803    0.2069    0.0768    0.2121    1.1690    2.0610   19.2100    0.0064    0.0594    0.0550    0.0163    0.0196    0.0081   15.0300   32.0100  108.8000   697.7000    0.1651    0.7725    0.6943    0.2208    0.3596    0.1431\n",
      "  15       0.0000   14.5400   27.5400   96.7300   658.8000    0.1139    0.1595    0.1639    0.0736    0.2303    0.0708    0.3700    1.0330    2.8790   32.5500    0.0056    0.0424    0.0474    0.0109    0.0186    0.0055   17.4600   37.1300  124.1000   943.2000    0.1678    0.6577    0.7026    0.1712    0.4218    0.1341\n",
      "  16       0.0000   14.6800   20.1300   94.7400   684.5000    0.0987    0.0720    0.0740    0.0526    0.1586    0.0592    0.4727    1.2400    3.1950   45.4000    0.0057    0.0116    0.0200    0.0111    0.0141    0.0021   19.0700   30.8800  123.4000  1138.0000    0.1464    0.1871    0.2914    0.1609    0.3029    0.0822\n",
      "  17       0.0000   16.1300   20.6800  108.1000   798.8000    0.1170    0.2022    0.1722    0.1028    0.2164    0.0736    0.5692    1.0730    3.8540   54.1800    0.0070    0.0250    0.0319    0.0130    0.0169    0.0041   20.9600   31.4800  136.8000  1315.0000    0.1789    0.4233    0.4784    0.2073    0.3706    0.1142\n",
      "  18       0.0000   19.8100   22.1500  130.0000  1260.0000    0.0983    0.1027    0.1479    0.0950    0.1582    0.0539    0.7582    1.0170    5.8650  112.4000    0.0065    0.0189    0.0339    0.0152    0.0136    0.0020   27.3200   30.8800  186.8000  2398.0000    0.1512    0.3150    0.5372    0.2388    0.2768    0.0761\n",
      "  19       1.0000   13.5400   14.3600   87.4600   566.3000    0.0978    0.0813    0.0666    0.0478    0.1885    0.0577    0.2699    0.7886    2.0580   23.5600    0.0085    0.0146    0.0239    0.0132    0.0198    0.0023   15.1100   19.2600   99.7000   711.2000    0.1440    0.1773    0.2390    0.1288    0.2977    0.0726\n",
      "  20       1.0000   13.0800   15.7100   85.6300   520.0000    0.1075    0.1270    0.0457    0.0311    0.1967    0.0681    0.1852    0.7477    1.3830   14.6700    0.0041    0.0190    0.0170    0.0065    0.0168    0.0024   14.5000   20.4900   96.0900   630.5000    0.1312    0.2776    0.1890    0.0728    0.3184    0.0818\n",
      "====  ===========  ========  ========  ========  =========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  ========  =========  ========  ========  ========  ========  ========  ========\n"
     ]
    }
   ],
   "source": [
    "# Cargar y preparar los datos\n",
    "file_path = \"../data/raw/data.csv\"\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Crear nombres cortos para las características\n",
    "feature_names = [f'feat{str(i+1).zfill(2)}' for i in range(30)]\n",
    "\n",
    "# Eliminar columna ID y asignar nombres a las columnas\n",
    "df = df.drop([0], axis=1)  # El ID no aporta información\n",
    "df.columns = ['diagnosis'] + feature_names\n",
    "\n",
    "# Mapear diagnóstico de M/B a 0/1\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 0, 'B': 1})\n",
    "\n",
    "# Mostrar los primeros registros en formato tabla\n",
    "print(\"\\nPrimeros registros del dataset:\\n\")\n",
    "print(tabulate(df.head(21), headers='keys', tablefmt='rst', showindex=True, floatfmt='.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2a909-2f7c-4207-9538-00bb4ee299da",
   "metadata": {},
   "source": [
    "### Dividir en características (X) y target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5d0ccb-d371-4f62-9d55-d99ba404bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de dimensiones:\n",
      "X shape: (569, 30)\n",
      "y shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "# X variable con 30 características independientes, y con una característica dependiente\n",
    "X = df[feature_names].values  # Convertir a numpy array\n",
    "y = df['diagnosis'].values    # Convertir a numpy array\n",
    "\n",
    "# Verificar las dimensiones\n",
    "print(\"\\nVerificación de dimensiones:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a6579a-11b3-4443-925f-c5690e5531b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del modelo:\n",
      "Precisión del modelo: 0.93\n",
      "Reporte de clasificación:\n",
      "{'precision': np.float64(0.9846153846153847), 'recall': np.float64(0.9014084507042254), 'f1_score': np.float64(0.9411764705882353), 'accuracy': np.float64(0.9292035398230089)}\n"
     ]
    }
   ],
   "source": [
    "# Normalizar los datos\n",
    "scaler = StandardScalerManual()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split_manual(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el perceptrón\n",
    "perceptron = PerceptronManual(learning_rate=0.01, n_iterations=1000)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score_manual(y_test, y_pred)\n",
    "report = classification_report_manual(y_test, y_pred)\n",
    "\n",
    "print(\"\\nResultados del modelo:\")\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
